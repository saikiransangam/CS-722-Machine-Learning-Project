{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS 722 Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gy-b_1XmStL",
        "outputId": "ce59fe40-2b69-4fd9-ca6e-0f4eaa76bad7"
      },
      "source": [
        "!pip install efficientnet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.5.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.15.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HASCVhwNmV7V"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import shutil\n",
        "sys.path.append('..')\n",
        "from IPython.display import Image\n",
        "\n",
        "User_tfKeras = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WERNkDRjmaJ8"
      },
      "source": [
        "if User_tfKeras:\n",
        "    from tensorflow.keras import models\n",
        "    from tensorflow.keras import layers\n",
        "    from tensorflow.keras import optimizers\n",
        "\n",
        "    from efficientnet.tfkeras import EfficientNetB6\n",
        "    from efficientnet.tfkeras import EfficientNetL2\n",
        "    from efficientnet.tfkeras import center_crop_and_resize, preprocess_input\n",
        "else:\n",
        "    from keras import models\n",
        "    from keras import layers\n",
        "    from keras import optimizers\n",
        "\n",
        "    from efficientnet.keras import EfficientNetB6\n",
        "    from efficientnet.keras import EfficientNetL2\n",
        "    from efficientnet.keras import center_crop_and_resize, preprocess_input"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsQIFrvdmvXI"
      },
      "source": [
        "batch_size = 48\n",
        "\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 500\n",
        "NUM_TRAIN = 2000\n",
        "NUM_TEST = 1000\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIQIOWmmyRY",
        "outputId": "96304192-7223-446a-f2c4-0c166743f240"
      },
      "source": [
        "if not os.path.isfile(\"kagglecatsanddogs_3367a.zip\"):\n",
        "  !wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
        "  !unzip -qq kagglecatsanddogs_3367a.zip -d dog_vs_cat\n",
        "else:\n",
        "  print(\"dataset already exist.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 03:05:44--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.201.212.130, 2600:1402:9800:4b7::e59, 2600:1402:9800:48a::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.201.212.130|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘kagglecatsanddogs_3367a.zip’\n",
            "\n",
            "kagglecatsanddogs_3 100%[===================>] 786.68M   167MB/s    in 4.9s    \n",
            "\n",
            "2021-11-22 03:05:49 (162 MB/s) - ‘kagglecatsanddogs_3367a.zip’ saved [824894548/824894548]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDfWrb_zm8_p",
        "outputId": "9a014d6f-1441-43d8-b06b-4fa6de243667"
      },
      "source": [
        "original_dataset_dir = './dog_vs_cat/PetImages'\n",
        "\n",
        "cat_images = glob.glob(os.path.join(original_dataset_dir, \"Cat\", '*.jpg'))\n",
        "dog_images = glob.glob(os.path.join(original_dataset_dir, \"Dog\", '*.jpg'))\n",
        "print(\"total cat images: {}\\n\\rtotal dog images: {}\".format(len(cat_images), len(dog_images)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total cat images: 12500\n",
            "\rtotal dog images: 12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lszUYG3zm_5Z"
      },
      "source": [
        "base_dir = './data/dog_vs_cat_small'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.makedirs(train_cats_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.makedirs(train_dogs_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.makedirs(validation_cats_dir, exist_ok=True)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.makedirs(validation_dogs_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.makedirs(test_cats_dir, exist_ok=True)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.makedirs(test_dogs_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "fnames = cat_images[:NUM_TRAIN//2]\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_cats_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "offset = NUM_TRAIN//2\n",
        "\n",
        "fnames = cat_images[offset:offset + NUM_TEST // 2]\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_cats_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "offset = offset + NUM_TEST // 2\n",
        "\n",
        "fnames = cat_images[offset:offset + NUM_TEST // 2]\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_cats_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "\n",
        "fnames = dog_images[:NUM_TRAIN//2]\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_dogs_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "offset = NUM_TRAIN//2\n",
        "\n",
        "fnames = dog_images[offset:offset + NUM_TEST // 2]\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_dogs_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "offset = offset + NUM_TEST // 2\n",
        "\n",
        "\n",
        "fnames = dog_images[offset:offset + NUM_TEST // 2]\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_dogs_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1UTj21snOkl",
        "outputId": "0f26fcc9-8840-469c-fcf4-b890e80b0bfe"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n",
            "total test cat images: 500\n",
            "total test dog images: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3tOGV1tnTYh",
        "outputId": "53d800ff-20b0-4b0c-f9b6-b6531d25171f"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to target height and width.\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    }
  ]
}